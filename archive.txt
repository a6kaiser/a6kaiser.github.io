Hello! I'm Alexandre Kaiser, a current Master's student in Computer Science at NYU Courant. Before that, I received my Bachelor's in Applied Mathematics from Northwestern University. I am honored to be advised by Arthur Jacot for my Master's thesis researching deep learning optimization for continual learning tasks. Aside from my studies, my recent work experience includes teaching, tutoring, engineering and a data scientist.

My goal is to work towards a world that strikes a better balance between innovation and wastefulness. As that is an optimization problem, I turn to my background in Applied Mathematcs which taught me the strength of utilizing abstractions to solve any and all applicable real-world tasks. However, most real-world tasks that I am interested in—education, governance, leadership—are too complex to be abstracted. I chose to study machine learning in the hope that one more layer of abstraction from the problem would enable us to model a machine which in turn can model any task.

My research interests lie particularly in the role of optimization on a model’s implicit bias and scaling properties, thus how features and symmetries develop in deep learning models. This includes research on how the loss surface lends itself to emergent behavior in practice. Though my research is theoretical, I am motivated by a desire to improve the usefulness of algorithms in practice. Agnostic to the task or even its modalities, I aim to improve our understanding of deep learning models to better predict their behavior in real-world applications.